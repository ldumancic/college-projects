{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmdu1CpaMLob"
   },
   "source": [
    "<center>\n",
    "Obrada prirodnog jezika\n",
    "\n",
    "Lemmatization\n",
    "\n",
    "Lucija Dumančić"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEBaZofsbC2Z"
   },
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3562,
     "status": "ok",
     "timestamp": 1711828180908,
     "user": {
      "displayName": "Marko Kumir",
      "userId": "15629419082931327730"
     },
     "user_tz": -60
    },
    "id": "_wqvDMKjn8TH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1711828180908,
     "user": {
      "displayName": "Marko Kumir",
      "userId": "15629419082931327730"
     },
     "user_tz": -60
    },
    "id": "gYg0mHxvqNHj",
    "outputId": "0680fb80-7e41-431a-c66e-3e9f54e3b1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/OPJ/Projekt\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/OPJ/Projekt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1Ay90e76CRk"
   },
   "source": [
    "##Load train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 23763,
     "status": "ok",
     "timestamp": 1711828204668,
     "user": {
      "displayName": "Marko Kumir",
      "userId": "15629419082931327730"
     },
     "user_tz": -60
    },
    "id": "zJ8PQQaEoZ5g"
   },
   "outputs": [],
   "source": [
    "# Load train arrays from files\n",
    "vectorized_tokens_train_val = np.load('vectorized_tokens_train.npy')\n",
    "vectorized_lemmas_train_val = np.load('vectorized_lemmas_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1711828204669,
     "user": {
      "displayName": "Marko Kumir",
      "userId": "15629419082931327730"
     },
     "user_tz": -60
    },
    "id": "AX4h6mTgSzjb"
   },
   "outputs": [],
   "source": [
    "# Used for splitting train and validation vectors\n",
    "split_index = int(len(vectorized_tokens_train_val) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1711828204670,
     "user": {
      "displayName": "Marko Kumir",
      "userId": "15629419082931327730"
     },
     "user_tz": -60
    },
    "id": "JbAE8Uu4SiA0"
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "vectorized_tokens_train = vectorized_tokens_train_val[:split_index]\n",
    "vectorized_lemmas_train = vectorized_lemmas_train_val[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1711828204670,
     "user": {
      "displayName": "Marko Kumir",
      "userId": "15629419082931327730"
     },
     "user_tz": -60
    },
    "id": "p1IAkaGZTQc9"
   },
   "outputs": [],
   "source": [
    "# Validation data\n",
    "vectorized_tokens_val = vectorized_tokens_train_val[split_index:]\n",
    "vectorized_lemmas_val = vectorized_lemmas_train_val[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1711828204670,
     "user": {
      "displayName": "Marko Kumir",
      "userId": "15629419082931327730"
     },
     "user_tz": -60
    },
    "id": "RqHwuxxqR-Zp",
    "outputId": "8523a0e4-b8fc-4ebb-96b3-69420affeb52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439554\n",
      "109889\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorized_tokens_train))\n",
    "print(len(vectorized_tokens_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAQES-4B6bjF"
   },
   "source": [
    "We utilized 439,554 vectorized tokens and lemmas for training the model, and the remaining portion, consisting of 109,889 vectorized tokens and lemmas, was allocated for validation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ken6OEX6Qhw"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4x-ehG6RwJcy"
   },
   "outputs": [],
   "source": [
    "# Define and compile the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(vectorized_tokens_train.shape[1],)),   # Input layer with 128 neurons and ReLU activation function\n",
    "    Dense(64, activation='relu'),   # Hidden layer with 64 neurons and ReLU activation function\n",
    "    Dense(vectorized_lemmas_train.shape[1])   # Output layer with a number of neurons equal to the dimensionality of the output (lemmas)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='cosine_similarity')   # Cosine similarity loss function is used for regression tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79ORy2B952Fk"
   },
   "source": [
    "In this code cell, a neural network model is defined using the Keras Sequential API. It comprises three Dense layers: an input layer with 128 neurons utilizing ReLU activation, a hidden layer with 64 neurons also employing ReLU activation, and an output layer with a dynamic number of neurons equal to the dimensionality of the output (lemmas). The model is compiled with the Adam optimizer and utilizes cosine similarity as the loss function, making it suitable for regression tasks, particularly for predicting vectors closer in direction to the target vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 433773,
     "status": "ok",
     "timestamp": 1711747244906,
     "user": {
      "displayName": "Marko Kumir",
      "userId": "15629419082931327730"
     },
     "user_tz": -60
    },
    "id": "X-6Qk171wv7o",
    "outputId": "bc3a338f-9c68-42c9-ef5a-6a4f9409e5aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6869/6869 [==============================] - 24s 3ms/step - loss: -0.7255 - val_loss: -0.7251\n",
      "Epoch 2/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7467 - val_loss: -0.7292\n",
      "Epoch 3/20\n",
      "6869/6869 [==============================] - 22s 3ms/step - loss: -0.7496 - val_loss: -0.7310\n",
      "Epoch 4/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7526 - val_loss: -0.7338\n",
      "Epoch 5/20\n",
      "6869/6869 [==============================] - 22s 3ms/step - loss: -0.7539 - val_loss: -0.7333\n",
      "Epoch 6/20\n",
      "6869/6869 [==============================] - 22s 3ms/step - loss: -0.7546 - val_loss: -0.7349\n",
      "Epoch 7/20\n",
      "6869/6869 [==============================] - 22s 3ms/step - loss: -0.7559 - val_loss: -0.7359\n",
      "Epoch 8/20\n",
      "6869/6869 [==============================] - 22s 3ms/step - loss: -0.7565 - val_loss: -0.7337\n",
      "Epoch 9/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7568 - val_loss: -0.7365\n",
      "Epoch 10/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7578 - val_loss: -0.7375\n",
      "Epoch 11/20\n",
      "6869/6869 [==============================] - 22s 3ms/step - loss: -0.7583 - val_loss: -0.7364\n",
      "Epoch 12/20\n",
      "6869/6869 [==============================] - 22s 3ms/step - loss: -0.7585 - val_loss: -0.7376\n",
      "Epoch 13/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7587 - val_loss: -0.7389\n",
      "Epoch 14/20\n",
      "6869/6869 [==============================] - 22s 3ms/step - loss: -0.7589 - val_loss: -0.7386\n",
      "Epoch 15/20\n",
      "6869/6869 [==============================] - 22s 3ms/step - loss: -0.7591 - val_loss: -0.7391\n",
      "Epoch 16/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7593 - val_loss: -0.7387\n",
      "Epoch 17/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7594 - val_loss: -0.7390\n",
      "Epoch 18/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7595 - val_loss: -0.7387\n",
      "Epoch 19/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7597 - val_loss: -0.7381\n",
      "Epoch 20/20\n",
      "6869/6869 [==============================] - 21s 3ms/step - loss: -0.7598 - val_loss: -0.7395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7bf788528f40>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(vectorized_tokens_train, vectorized_lemmas_train,\n",
    "          validation_data=(vectorized_tokens_val, vectorized_lemmas_val), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzftPhpl5_Kd"
   },
   "source": [
    "The model is trained using the fit method. Training data vectorized_tokens_train and corresponding target data vectorized_lemmas_train are provided for learning. Additionally, validation data (vectorized_tokens_val, vectorized_lemmas_val) is used to evaluate the model's performance during training. The training process lasts for 20 epochs with a batch size of 64 samples. During each epoch, the model adjusts its parameters to minimize the specified loss function, optimizing its ability to predict lemmas based on tokenized input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZgKA30jgUQjZ"
   },
   "outputs": [],
   "source": [
    "#Save and export lemmatization model\n",
    "model.save(\"lemmatization_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOO5EwxOizq2m5a0UjhXQjw",
   "gpuType": "V100",
   "machine_shape": "hm",
   "mount_file_id": "1rJA6zc_v8X3TZcpexOgABQh8hQNl7alR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
